{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Pytorch MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vogliamo modellare un multi-layer perceptron utilizzando **Pytorch** per classificare il dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 0.4.1.post2 CUDA: False\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print('Using PyTorch version:', torch.__version__, 'CUDA:', cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dati\n",
    "Vogliamo utilizzare il dataset MNIST, si può scaricare direttamente o caricarlo dai documenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vogliamo ora estrarre le prime tre classi in modo da fare il train solo su queste.\n",
    "\n",
    "Inoltre dividiamo il dataset così creato in train (80%) e validate (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(np.floor(len(train_loader.dataset.train_labels))*0.8)\n",
    "\n",
    "train_l = train_loader.dataset.train_labels[0:split]\n",
    "train_d = train_loader.dataset.train_data[0:split]\n",
    "\n",
    "val_l = train_loader.dataset.train_labels[split:-1]\n",
    "val_d = train_loader.dataset.train_data[split:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14961\n"
     ]
    }
   ],
   "source": [
    "zeros = train_d[train_l == 0]\n",
    "ones = train_d[train_l == 1]\n",
    "twos = train_d[train_l == 2]\n",
    "\n",
    "\n",
    "train_data012 = torch.cat([zeros, ones, twos])\n",
    "train_labels012 = torch.cat([torch.zeros((len(zeros),)), torch.ones((len(ones),)), 2.0*torch.ones((len(twos),))])\n",
    "\n",
    "# ADB: Qui ho notato che c'e' un problema: le immagini sono int8, ma devono essere float32.\n",
    "# Faccio la conversione e divido per 255.0 (cosi' i pixel sono fra 0.0 e 1.0).\n",
    "train_data012 = train_data012.type(torch.float32) / 255.0\n",
    "\n",
    "print(len(train_data012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13868\n"
     ]
    }
   ],
   "source": [
    "threes = train_d[train_l == 3]\n",
    "fours = train_d[train_l == 4]\n",
    "fives = train_d[train_l == 5]\n",
    "\n",
    "\n",
    "train_data345 = torch.cat([threes, fours, fives])\n",
    "train_labels345 = torch.cat([3.0*torch.ones((len(threes),)), 4.0*torch.ones((len(fours),)), 5.0*torch.ones((len(fives),))])\n",
    "\n",
    "# ADB: Qui ho notato che c'e' un problema: le immagini sono int8, ma devono essere float32.\n",
    "# Faccio la conversione e divido per 255.0 (cosi' i pixel sono fra 0.0 e 1.0).\n",
    "train_data345 = train_data345.type(torch.float32) / 255.0\n",
    "\n",
    "print(len(train_data345))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3662\n"
     ]
    }
   ],
   "source": [
    "zeros = val_d[val_l == 0]\n",
    "ones = val_d[val_l == 1]\n",
    "twos = val_d[val_l == 2]\n",
    "\n",
    "\n",
    "val_data012 = torch.cat([zeros, ones, twos])\n",
    "val_labels012 = torch.cat([torch.zeros((len(zeros),)), torch.ones((len(ones),)), 2.0*torch.ones((len(twos),))])\n",
    "\n",
    "# ADB: Qui ho notato che c'e' un problema: le immagini sono int8, ma devono essere float32.\n",
    "# Faccio la conversione e divido per 255.0 (cosi' i pixel sono fra 0.0 e 1.0).\n",
    "val_data012 = val_data012.type(torch.float32) / 255.0\n",
    "\n",
    "print(len(val_data012))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso creiamo dei nuovi dataset per il train in modo da vedere come reagisce il classificatore con dati ID e OOD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3147\n"
     ]
    }
   ],
   "source": [
    "test_l012 = test_loader.dataset.test_labels\n",
    "test_d012 = test_loader.dataset.test_data\n",
    "\n",
    "zeros = test_d012[test_l012 == 0]\n",
    "ones = test_d012[test_l012 == 1]\n",
    "twos = test_d012[test_l012 == 2]\n",
    "\n",
    "\n",
    "test_data012 = torch.cat([zeros, ones, twos])\n",
    "test_labels012 = torch.cat([torch.zeros((len(zeros),)), torch.ones((len(ones),)), 2.0*torch.ones((len(twos),))])\n",
    "\n",
    "# ADB: Qui ho notato che c'e' un problema: le immagini sono int8, ma devono essere float32.\n",
    "# Faccio la conversione e divido per 255.0 (cosi' i pixel sono fra 0.0 e 1.0).\n",
    "test_data012 = test_data012.type(torch.float32) / 255.0\n",
    "print(len(test_data012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2884\n"
     ]
    }
   ],
   "source": [
    "test_l = test_loader.dataset.test_labels\n",
    "test_d = test_loader.dataset.test_data\n",
    "\n",
    "threes = test_d[test_l == 3]\n",
    "fours = test_d[test_l == 4]\n",
    "fives = test_d[test_l == 5]\n",
    "\n",
    "test_data345 = torch.cat([threes, fours, fives])\n",
    "test_labels345 = torch.cat([3.0*torch.ones((len(threes),)), 4.0*torch.ones((len(fours),)), 5.0*torch.ones((len(fives),))])\n",
    "\n",
    "# ADB: Qui ho notato che c'e' un problema: le immagini sono int8, ma devono essere float32.\n",
    "# Faccio la conversione e divido per 255.0 (cosi' i pixel sono fra 0.0 e 1.0).\n",
    "test_data345 = test_data345.type(torch.float32) / 255.0\n",
    "print(len(test_data345))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso possiamo utilizzare i nuovi dataset creati per train, validation e test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data012' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a916389b7de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train012 80%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_ds012\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data012\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels012\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_loader012\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds012\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data012' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Train012 80%\n",
    "train_ds012 = TensorDataset(train_data012, train_labels012)\n",
    "train_loader012 = torch.utils.data.DataLoader(train_ds012, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# Validation012 20%\n",
    "validation_ds012 = TensorDataset(val_data012, val_labels012)\n",
    "validation_loader012 = torch.utils.data.DataLoader(validation_ds012, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# Test012 all\n",
    "test_ds012 = TensorDataset(test_data012, test_labels012)\n",
    "test_loader012 = torch.utils.data.DataLoader(test_ds012, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "######### da costruire train validation e test di 345 e riprovare esecuzione\n",
    "# Train345 80%\n",
    "train_ds345 = TensorDataset(train_data012, train_labels012)\n",
    "train_loader012 = torch.utils.data.DataLoader(train_ds012, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# Validation345 20%\n",
    "validation_ds012 = TensorDataset(val_data012, val_labels012)\n",
    "validation_loader012 = torch.utils.data.DataLoader(validation_ds012, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# Test345 all\n",
    "test_ds345 = TensorDataset(test_data345, test_labels345)\n",
    "test_loader345 = torch.utils.data.DataLoader(test_ds345, batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADB: Osservazioni\n",
    "\n",
    "- Dati IN DISTRIBUTION per training (il train_loader012 va bene per questo). \n",
    "- Dati IN DISTRIBUTION per validation (i.e. per monitorare quanto bene classifichiamo le classi IN DISTRIBUTION). NON abbiamo questi data per la validation per ora.  \n",
    "- Dati OUT OF DISTRIBUTION (OOD) per i test finali (questo abbiamo, ma abbiamo chiamato 'validation'). Non possiamo usare questi dati nella funzione validate() sotto, per esempio, perche' non abbiamo ettichette e perche' non sono IN DISTRIBUTION. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Proviamo a stampare le prime 10 immagini del train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# ADB: qui ho modificato perche' ora ogni batch contiene un gruppo di immagini e anche un gruppo di label.\n",
    "for (X_train, y_train) in train_loader012:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :].numpy().reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Proviamo a stampare le prime 10 immagini del validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_train: torch.Size([32, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "for (V_train, y_train) in validation_loader012:\n",
    "    print('V_train:', V_train.size(), 'type:', V_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABSCAYAAABwglFkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFsxJREFUeJzt3Xd4FFUXx/HvinlF0YioYEBEgmA3il1BREApVqyPFEVFQEQFUUBBAQUUBAsgFqwoVhDbgw1J7AVbVJq9gNgQK1KSvH/sc+7sJpuwuzPb8Pf5R9xsNncyk5l7zz333FBFRQUiIiIikpxNMt0AERERkVymzpSIiIiID+pMiYiIiPigzpSIiIiID+pMiYiIiPigzpSIiIiID+pMiYiIiPigzpSIiIiID+pMiYiIiPigzpSIiIiID5um84eFQqGc3rumoqIitKH3bOzHuLEfH+gYc4GOceM/PtAx5gIdY5giUyIiIiI+qDMlIiIi4oM6UyIiIiI+bBSdqby8PPLy8qhXrx716tVjyJAhzJs3j3nz5rF27VrWrl3L8OHDGT58OJtttlmmmysiIpI1zj33XMrKyigrK6OiooKKigqaNWuW6WYlrHbt2vTs2ZOePXsyY8YMZsyY4Y7nrrvuoqCggIKCgpT87I2iMyUiIiKSKWldzRekTTcNN71///60a9cOgGOPPdZ9fdWqVVHvGz16NAC//vor06ZNS2dTpRqbbBLuy3fr1o2rr74agL59+wLw0ksvZaxdqdKmTRsAzj77bADOOuusat+7dOlSunbtCsDChQtT3rYgjBw50p1HM2rUKEaOHJmZBgWodu3aALRv355jjjkGgH322QeA0tJS/vnnHwCmTp0KwLfffpuBVqbG/PnzadGiBQBt27YFwtdnrtp11125/fbbo1679957uffeezPToDTaY489ADjggAMAuPLKKwEoKCigoiK84K68vNy994svvshAKxOXn58PwJtvvsnuu+8OwG+//QbA2rVrAejVq5d7/7nnnht4GxSZEhEREfEh5yJTO+20E+CNALt06cJff/0FwEMPPQTA7NmzWbJkCQC9e/cGYMCAAQCMHTuWN998E4APP/wwfQ2XKi666CIAJk2a5Ebyn3/+OQCbbbYZa9asyVjbUsEipxaRspFgLM2bN3fXZ58+fQC45557UtzC5Bx55JEAVaJSGwOLbNv9JnJ0a1q3bu3+bfeb0047Ddg4IqwVFRWEQuEyO/b7yEU33XQTEJ7NqFWrFoA7rtatW7N8+XIAXnjhhcw0MMWKioqYPXs2gIuk1pQXNXDgQF5++WUA/v7779Q3MAmW/3TjjTcC4fN5zjnnAN7fXrdu3QAYN25cStuSM38ZJ510EgATJ04EYOeddwaguLiYwYMHA/D+++9X+b5LL70UwHW4evXqxahRowDv5q9OVWYccsgh7t8WYt9yyy2B8NTC22+/DeA6xg8++CAAf/75ZxpbGYwuXbq4TtSkSZMAYk4r7LDDDgAMHTrUTanYg3zhwoXud5JN5s+fH9f7Yk33ZfsUoHVkrRO1fv16N0Vk96LddtvNTZccfvjhAO6hNWzYMHf+ck3jxo0B2HHHHfn++++B3JlyjvTpp58C4fMEXgcKvAFNKBRizpw5gHdeR4wYkc5mBs6O06a9unXrRpMmTaK+VtOA7ogjjqBVq1YAPP/886lsatJOOeUUABo2bAhA586d+frrr6PeU1pampa2aJpPRERExIeciUw1atQI8Kb5pk+fDoRH8CtXrqz2+9avXw94iXZNmzbljDPOAKBBgwYAdOjQIePRjvz8fFe2wUaENsp9+OGH+fXXXwEvOTCXWWh5//33d6/Zvy0xsFGjRlGRK4COHTsC4dGInddsZaNhSzrfa6+9XGRq7ty51X7fJ598AoQjrsuWLQNgu+22A2Dw4MGceuqpKWtzvBKd1qtp9GufYVG44uJiX20LmkUCLRF35syZXHzxxQA88MADADz33HOUlJQAMGTIEAAuv/xyAK677jpef/11IPci4Lvssov7b65F13r16sVhhx0GhBPOwYvGjB49mueeew6AJ554Agg/C2yRgS0QsSicpY/kGlvA8t577wHQqVOnKu+x380XX3zBySefDMCjjz7qvn7EEUcA2RuZmjx5ctR/N6SoqAjwZkBsxioIikyJiIiI+JAzkaktttgC8PJNbOSXqA8++MBFpn7++WcAVq9eHUALE2PLqi+55BIgHB2z6FtlN998sxst2PtXrFiRhlYGyyIsNiqMTH7s0qULAO+++y4QnUtz1VVXAXD88ccDsO+++7JgwYKUt9ePoUOHAvDLL78AcP311yf0/evXr68S0cnLywumcT5ZNMkiVGbUqFFJJ6Fb3lXbtm2zKjpl15lFJ0aMGMFHH30EwDfffOPeZ/cQu2732msvIBwdGDRoEAA9e/ZMS5v9sijhY4895l575plnMtWchHz22WcAFBYWRuVGgVceZ8yYMaxbtw6AE044AYA5c+a4fEW7D99///1AuERAtudPWQTclJSUuPIHlni/oWKVs2bNAuCaa64BYPjw4S66ZTM7uSjyOWN/u0FGpEzOdKbGjx8PwP/+9z9fn/Piiy+6B5vVnygrK/PXuCQMGzYMgNNPP73K1/7991/Aa19+fr4LwVrYtWvXrrz11lvpaGpgLLRaeQXJmjVreOONNwDo3r07AD/88IP7ev/+/QFv+nPAgAE11mjKBk8//XSmm5AS8+fPr9KJMsXFxVWm7WK9175mn1f58ys/BDNp6623BryFLOAthqlpQHPdddcB4QGATTfZYMI62NnKprvq1auX4ZYkzjpEkdeQLTgaO3YsgOtIAbzzzjtA+JzaogHrdNiKP5u6hexLSq9bty7grfTddtttAXjttddcWoQNypYvX859990H4KaeI++zxj4rFbWY0qlly5ZA9Cq+RYsWpeznaZpPRERExIeciUwZi9Yka9myZW6pvY0we/fuzR133OG7bYl49tlnAS8pMD8/n6+++grwQpBWH6Nhw4YuBGsjr/Hjx7sQtVV6zXb2+66suLg4ZnJkdfbZZx8XMfj9998DaVsQatWq5ZJXrW7Wiy++mMEWBcciTDVFmoqLi6skkhcXF7spCIsQRE7jxVqibT8jG6b7+vXrB8Dmm28OhHdWiOeas+nBdevWUVhYCHgLXrI9MlXZ+++/z2uvvZbpZtTI6ntZOkgki8ZERqQqe/vtt92Ull2nRx99NBCurWXT9iYbIlSnnHKKi9rbwixjVfoBrr32WiAccYqcmq6OvcdqUeUquxbq1KkDwNdff+2mblNBkSkRERERH3IuMuXXzz//7HretizUCoCmky2rtkJxtWrVclE3K7JmS5PnzJnj9qybMWMGAK1ataJp06ZA7kSm9txzz6j/t9wwy4eLV2lpaVZFpMywYcPcqNZKN1hOnJ3nDbHRVOfOndlqq61S0MrkxCrMGRl9qvxapMgcqepEFtK1vKtMRqZ23HFHwIsOm/PPPz/pv7fmzZsDXtmMXLF69eqsrYBtLL8rMlfKyh5YZfMNsTIYdq999dVXgXBCuuVPWYRqyZIl7h6ebvZceOSRR2p835QpU4DkC+OGQiHq168PeLm6r7zySlKflU7bb7894C1WM9OmTeOnn35K2c9VZEpERETEh/9cZKqwsJD99tsv6rW77rorQ62JvUTTtsWJ3B4n00VFg2Dbp9jO5TZ/Xd12JNtssw3gzXlnKyu22qFDB/fa0qVLgfhHxcZKZsQaddpqo3SKNaq1iFE8EadkVLdaMJ1syxiLpn788ccAPPnkk0l/pl3PEjyL1kSyMiuJ5tnadiS2Vcns2bOrrPC7+uqr3QrkL7/8Mqk2J8pyD221XWSeoZX5iSwZYyUOEmUzNZtvvrmL5ORCRMpYKQgrDWEFd1MdSfzPdaZatmzpwoC5xJIozerVq3MuQdCSWG2p+IbY+2x6xNgefdnCOom2jxV4yfa2cXO89t133yqvWccqsu5PJtmU3MbMEs6NVaOvKYk5lhdeeMEtFLFl+BK8yjW8li1bxp133unrM23ab8qUKVx44YWAVzahWbNmrl5eixYtfP2ceNStW9fVVoxMNrdAgC2gsmrnftg+lAUFBa5uV7azlIgJEyZw5plnAl4i/VFHHQXELgMRJE3ziYiIiPjwn4lMWcHIyOJ72c6SKTt27FglGfnaa69l8eLFmWhW2lQebb788suAlxiaaXYtRRZetemhRCNSNk0xbdo0IDqEb8ediUr9sWRDyYJU6tKli9sr0vbTS7RIrJ3Pli1b8uOPPwLZVcYjEVbmI1v17NmTTTeNfpQ99dRTbj9Tv8aNG+fuOZHTXZXLEaRSjx49osodADz++OP06dMnsJ9h05rDhw8Hat5TM0g2dVq/fn1XPuScc86J63utIOeJJ54IhBeIWPTY9pP87rvvAm1vdRSZEhEREfEh5yNTHTt2rFJK4OSTT3bJh5anM3jwYCBcbt96qra9QDyFzDLBRj5W4BNwCYETJkzISJvS5aCDDqJz585Rr2VyL8XKioqKXOE+G8EtXbqUK664IqnPs+Ty8vJy99qaNWuAcN5NpiS7114ushHy6NGjXST4+eefB7xrL16W7Nq4cWO3wOL7778PqqkpVTkiPH369Ay1JD5NmjRJ+RZEVlA5U2655RZ3b1i1ahUAt956q+/PtWTzXr16uYjUJpuEYyzl5eXu36lg+Wc33ngjAKeddpr7muUoWjvAux9aSaBatWoxYMAAIDqKZls5pfsZmTOdKVvRZX80xx13HBC+adkJt19oKBRyG+fafyMrLdvJsQTuyAdYJtlx2Gq3mTNnVnnPxRdfDIT3KLSpS1vlYYnajRo1cvsy1cQqwVuINBvY/mXjxo1z59wSBydOnJixdlW23XbbuQeu1csaNGhQwjWIrBNl5zySJZxm+zRLECpv1JoJ1pmKXO1rScbxssr8kfvaWYcsV9igNJv2SPyvKy8vdwNp22Uh0RV2derUcfWijAUU9t57b/f8tOdhRUWF2xw6FawjZJ2oNWvWMGbMGMDrwIdCITd4tk6k7Ws7cuTImHv17r333oB3HSeacpEsTfOJiIiI+JDVkSlbntymTRu3LLxyzaH169e7uhJW7+Oggw6iR48egDe6WrlyJRCu62QRIFs6u+WWW7rE30waOHAgUHN48qGHHgLCYWcLdybKIh3ZVmIAwuFsiK5hZEt1I2uoZNoFF1zg/n399dcDMHfu3Li+1yIgI0aM4Pjjjwe869Qqp19yySXcdtttgbU3W1kdq8jaUtlUeiHeUa3dqyyabKPi4uLitO/7GZR0JSD7FWuvw2OOOcaVLLCab35YxNyUl5cHMs2WiEWLFgHEvU9i3bp1Aa96+cCBA2ndujUQe0/MyubOnZuWqKrVAbvssstc1fZIVsrIylNY6kFeXp5L0bFnWvPmzV0pEns+du/eHYBPPvkkVYcAKDIlIiIi4ktWRqasWKPNn0bmU9gyYxsxjh071i1btdFgZL6QJaJbIa/IkaYtNc2Gve0OOOAAt7t3TWxE0bRpU7dflkUzbE451s7YixcvdpE7682vWLHCf8MDYkvPbVQBXpSqpKQkI22KpXbt2gBRhV/jLeRoCZf9+vUD4Morr3Rfs3No5y4bIqWpduSRR8ZMcE92L7FMsnPbqVOnqNdPPPFE/vjjj0w0KSl16tRxFf1zxbRp09x1ZHvJFRYWuoU79jxJdBGB2XXXXZk1a1bUa3///TeDBg1KtslJsQiTLW6IXDhlz45TTz0VCLe5qKgIwEWj4mW5WN27d09LOQ97pp1++ulRZWaMRQVtL10zcuRIVw3eFpW1aNHCRfQt2m3Pj4MPPjil+VOKTImIiIj4EErnvHgoFKr2h+Xl5QHhHrZFKWyUcd999/Hwww8D3j47pm/fvq7nfeCBBwLhiEv//v0Bby+tIFbsVVRUbHB5S03HuCFWZMwiF7FYFO6bb75xuRg2XxzEqq8NHaOf4zO24slGUQUFBW6FhkV+wItC2pLYWKxwZuWRY3X8nkO7Jt977z0aNmwIeKsoa9qj67zzznORqCZNmlhb3NcnT54MhHOl/AryOrVl/bFympKNINlnxdqTsW3btnEVBU3F36KtDLLVmRAubQDRS7Ur22GHHVxuie2taFsM9e7d20UdE5WOv8XKTjjhBJ544omo19q1a1ft/pl+BHkO7X5v0ezIlYiWb2szHYsWLaoxmrztttsC3qq5fv360axZM2szEI4g29drEtQxRq5Cj1dkiYMNfW3VqlVuC6xEVwkme4wWzbX85r59+7pSDbHYnokWtZ80aRJlZWVV3mefYav6bMudlStXctFFFwGJl5uJ6xizpTNlS4kjkwnfeustANq3b+8eXNbRsGm7Bg0auEq3tpzy9ttvd7/4IKW6M7XFFlsA3lSXPXQjWYh31apV7qaf7M06llTdwNu0acOQIUMAbwNKC9+GQqG4kl0tRDtx4kQ3NWudqFh/VLEEdQ6ffPJJjj32WACGDh0KhBcOWCVmK1thtaj69+/vBgyRyZ+WVH/00UcDwVTJDvI6tQ5TrOm4RDtVNX2WLTiIt7p6ujpTds3GWhTSrl07AMaPH+/KKdjU+cEHHwz4q76szlTix2j3/caNG1db2uGxxx5zC5Ii60dZwrKliUTef+2zrDxBu3bt4kpoDuoYy8rKEl4QUFOSuS2WsaT2KVOmJD0YD+oY69evT35+frVft+lyOwfxsvvz4MGD3T24a9euAMybNy+uz4jnGDXNJyIiIuJD1kSmrOTBggULXKKZFev64YcfXI+18hLVkpISN+JNdaJyqiNT2SBVo+GpU6fWOH1pI3orxhqr4rAtof3rr7+SaQIQ3Dm8++673XS0RTJmzpxJYWEhED0tVplFEsePH8+kSZOAYBdBBHmd2nFYNKmm40pUcXGxi24lut9fKv4WbSTfo0cPN01nC1iseOG6devcNWrlMUKhkJsG7NChA0Ag+2YqMpX8MU6fPt3NXkSmDiTj33//dbMftsAg3mX2QR3jmDFjXMK7RVc25Omnnwa8Z+asWbNcJCrIkge58lxs1aqV+53YDMLYsWPd/n41UWRKREREJMWyJjJl6tSp48rL29y1JSoD3HDDDYC3W/Q///xTY4JykHKlB+5H0KNhy4VbsWJFlZ3dzdSpU93WKanedy+oc1hUVOQiobatzIZYtM32PnvjjTfi+r5EpfI6DeJ+kWh+VDXtSNkxbrXVVq4woiWx1mT+/Pn06dMHCHbrikxEpnbZZRcXhbI81aOOOiolUf9U309tMYAlG9u9qLr7UES7AFi+fDkQLqGzcOHCpNoQ5DHa1i92r4z0+OOPA14ZoTFjxlBaWgoknlCeqFx6Lh5yyCGAl++5YMGCqBI11cmpBPRckEsXTbKCvoFbUn1JSYmrA2Yr12xfutLS0rTtjxjkOWzUqBEQXrEF4dWHlnDeoEEDwEtwHD16tAux25RBqqT6OrWpvspTfm3atHGvxapiHmT9qFQfoz2U7AF26KGHuq/ZdPM111wDhFcLpaJmWyY6U+ANVC3hN55pkGSk+35q+19a8jF4iwgiE5EtwTmIyvV6ZoT9F45R03wiIiIiPigylQD1wDf+4wMdYy7QMW78xwc6xlygYwxTZEpERETEB3WmRERERHxQZ0pERETEB3WmRERERHxQZ0pERETEB3WmRERERHxIa2kEERERkY2NIlMiIiIiPqgzJSIiIuKDOlMiIiIiPqgzJSIiIuKDOlMiIiIiPqgzJSIiIuKDOlMiIiIiPqgzJSIiIuKDOlMiIiIiPqgzJSIiIuKDOlMiIiIiPqgzJSIiIuKDOlMiIiIiPqgzJSIiIuKDOlMiIiIiPqgzJSIiIuKDOlMiIiIiPqgzJSIiIuKDOlMiIiIiPqgzJSIiIuKDOlMiIiIiPqgzJSIiIuKDOlMiIiIiPvwffGF5sdImtEsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(V_train[i, :, :].numpy().reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Proviamo a stampare le prime 10 immagini del test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_train: torch.Size([32, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "for (T_train, y_train) in test_loader012:\n",
    "    print('T_train:', T_train.size(), 'type:', T_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(V_train[i, :, :].numpy().reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train: torch.Size([32, 28, 28]) type: torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "for Y_train in test_loader345:\n",
    "    print('Y_train:', Y_train.size(), 'type:', Y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(Y_train[i, :, :].numpy().reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron\n",
    "Definiamo ora la rete neurale come una Python class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc1_drop): Dropout(p=0.2)\n",
      "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2_drop): Dropout(p=0.2)\n",
      "  (fc3): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc1_drop = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc2_drop = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(128, 3)     # Numero di output 3.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc2_drop(x)\n",
    "        return F.log_softmax(self.fc3(x), 1)\n",
    "\n",
    "model = Net()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo le funzioni di **train** e **test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----con l'entropia\n",
    "#import torch.optim as optim\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch, log_interval, loader):\n",
    "    model.train()\n",
    "    batch_idx = 0\n",
    "    while(batch_idx != len(loader)):\n",
    "        for (data, target) in loader:\n",
    "            target = target.type(torch.long)\n",
    "            if cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            #loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(loader.dataset),\n",
    "                    100. * batch_idx / len(loader), loss.item()))\n",
    "            batch_idx = batch_idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(loss_vector, accuracy_vector, loader):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in loader:\n",
    "        target = target.type(torch.long)\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        val_loss += F.nll_loss(output, target).item()\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct / len(loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(loader.dataset), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, loader):\n",
    "    model.eval ()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    preds_list = []\n",
    "    for data, target in loader:\n",
    "        target = target.type(torch.long)\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data = Variable(data)\n",
    "        target = Variable(target)\n",
    "        output = model(data)\n",
    "        preds_list.append(output)\n",
    "        test_loss += F.nll_loss (output, target).item ()  # sum up batch loss\n",
    "        pred = output.max (1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "        correct += pred.eq (target.view_as (pred)).sum ().item ()\n",
    "    new_predict(preds_list)\n",
    "    test_loss /= len (loader.dataset)\n",
    "    print ('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format (\n",
    "        test_loss, correct, len (loader.dataset),\n",
    "        100. * correct / len (loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### rifaccio funzione predict che prende gli output di test li mette in numpy come matrice\n",
    "def new_predict(preds_list):\n",
    "    preds_list = torch.cat(preds_list)\n",
    "    preds_list = torch.exp(preds_list)\n",
    "    preds_list = preds_list.detach()\n",
    "    preds_list = preds_list.numpy()\n",
    "    preds_list = np.matrix(preds_list)\n",
    "    print('\\nLe probabilità di classificazione sono: ')\n",
    "    print(preds_list)\n",
    "    print('')\n",
    "    idness = np.max(preds_list, 1)\n",
    "    print ('\\nLa max probabilità è: ')\n",
    "    print(idness)\n",
    "    return idness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader):\n",
    "    preds = []\n",
    "    for data in data_loader :\n",
    "        data = Variable(data)\n",
    "        preds.append(model(data))\n",
    "        output = model(data)\n",
    "    preds = torch.cat(preds)\n",
    "    preds = torch.exp(preds)\n",
    "    preds = preds.detach()\n",
    "    preds = preds.numpy()\n",
    "    preds = np.matrix(preds)\n",
    "    print('\\nLe probabilità di classificazione sono: ')\n",
    "    print('')\n",
    "    print(preds)\n",
    "    idness = np.max(preds, 1)\n",
    "    print ('\\nLa max probabilità è: ')\n",
    "    print(idness)\n",
    "    return idness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo adesso addestrare il nostro modello, ogni epoca passa attraverso tutto il dataset del train. Dopo ogni epoca valutiamo il modello attraverso il test(). L'obiettivo è verificare che il modello riconosce come 0, 1, 2 anche le immagini di 3, 4, 5 quindi la classificazione è **out of distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATASET 012\n",
      "Train Epoch: 1 [0/3147 (0%)]\tLoss: 0.003035\n",
      "\n",
      "Validation set: Average loss: 0.0161, Accuracy: 3133/3147 (99%)\n",
      "\n",
      "Train Epoch: 2 [0/3147 (0%)]\tLoss: 0.012765\n",
      "\n",
      "Validation set: Average loss: 0.0161, Accuracy: 3133/3147 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/3147 (0%)]\tLoss: 0.021734\n",
      "\n",
      "Validation set: Average loss: 0.0141, Accuracy: 3135/3147 (99%)\n",
      "\n",
      "\n",
      "Le probabilità di classificazione sono: \n",
      "[[3.5914472e-05 5.9070313e-05 9.9990511e-01]\n",
      " [5.2671297e-03 2.8159782e-02 9.6657294e-01]\n",
      " [9.9999332e-01 1.1490399e-09 6.6943953e-06]\n",
      " ...\n",
      " [9.9996662e-01 4.7087457e-07 3.3139710e-05]\n",
      " [1.3966823e-06 9.9996805e-01 3.0562678e-05]\n",
      " [1.0626686e-04 7.7771561e-05 9.9981594e-01]]\n",
      "\n",
      "\n",
      "La max probabilità è: \n",
      "[[0.9999051 ]\n",
      " [0.96657294]\n",
      " [0.9999933 ]\n",
      " ...\n",
      " [0.9999666 ]\n",
      " [0.99996805]\n",
      " [0.99981594]]\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 3135/3147 (100%)\n",
      "\n",
      "\n",
      "DATASET 345\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1535491974311/work/aten/src/THNN/generic/ClassNLLCriterion.c:93",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-4323e712fe0e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, log_interval, loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;31m#loss = criterion(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1405\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1535491974311/work/aten/src/THNN/generic/ClassNLLCriterion.c:93"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "\n",
    "print('\\nDATASET 012')\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch, 100, train_loader012)\n",
    "    validate(lossv, accv, test_loader012)\n",
    "\n",
    "#test_loader012\n",
    "test(epoch, test_loader012)\n",
    "\n",
    "\n",
    "print('\\nDATASET 345')\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch, 100, test_loader345)\n",
    "    validate(lossv, accv, test_loader345)\n",
    "\n",
    "#test_loader345\n",
    "test(epoch, test_loader345)\n",
    "\n",
    "\n",
    "#average_precision_score(predict(test_loader012NoLab), test(epoch, test_loader012))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

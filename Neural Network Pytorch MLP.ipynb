{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Pytorch MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vogliamo modellare un multi-layer perceptron utilizzando **Pytorch** per classificare il dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 0.4.1.post2 CUDA: False\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print('Using PyTorch version:', torch.__version__, 'CUDA:', cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dati\n",
    "Vogliamo utilizzare il dataset MNIST, si può scaricare direttamente o caricarlo dai documenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vogliamo ora estrarre le prime tre classi in modo da fare il train solo su queste.\n",
    "\n",
    "Inoltre dividiamo il dataset così creato in train (80%) e validate (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(np.floor(len(train_loader.dataset.train_labels))*0.8)\n",
    "\n",
    "train_l = train_loader.dataset.train_labels[0:split]\n",
    "train_d = train_loader.dataset.train_data[0:split]\n",
    "\n",
    "val_l = train_loader.dataset.train_labels[split:-1]\n",
    "val_d = train_loader.dataset.train_data[split:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14961\n"
     ]
    }
   ],
   "source": [
    "zeros = train_d[train_l == 0]\n",
    "ones = train_d[train_l == 1]\n",
    "twos = train_d[train_l == 2]\n",
    "\n",
    "\n",
    "train_data012 = torch.cat([zeros, ones, twos])\n",
    "train_labels012 = torch.cat([torch.zeros((len(zeros),)), torch.ones((len(ones),)), 2.0*torch.ones((len(twos),))])\n",
    "\n",
    "# ADB: Qui ho notato che c'e' un problema: le immagini sono int8, ma devono essere float32.\n",
    "# Faccio la conversione e divido per 255.0 (cosi' i pixel sono fra 0.0 e 1.0).\n",
    "train_data012 = train_data012.type(torch.float32) / 255.0\n",
    "\n",
    "print(len(train_data012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3662\n"
     ]
    }
   ],
   "source": [
    "zeros = val_d[val_l == 0]\n",
    "ones = val_d[val_l == 1]\n",
    "twos = val_d[val_l == 2]\n",
    "\n",
    "\n",
    "val_data012 = torch.cat([zeros, ones, twos])\n",
    "val_labels012 = torch.cat([torch.zeros((len(zeros),)), torch.ones((len(ones),)), 2.0*torch.ones((len(twos),))])\n",
    "\n",
    "# ADB: Qui ho notato che c'e' un problema: le immagini sono int8, ma devono essere float32.\n",
    "# Faccio la conversione e divido per 255.0 (cosi' i pixel sono fra 0.0 e 1.0).\n",
    "val_data012 = val_data012.type(torch.float32) / 255.0\n",
    "\n",
    "print(len(val_data012))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso creiamo dei nuovi dataset per il train in modo da vedere come reagisce il classificatore con dati ID e OOD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3147\n"
     ]
    }
   ],
   "source": [
    "test_l012 = test_loader.dataset.test_labels\n",
    "test_d012 = test_loader.dataset.test_data\n",
    "\n",
    "zeros = test_d012[test_l012 == 0]\n",
    "ones = test_d012[test_l012 == 1]\n",
    "twos = test_d012[test_l012 == 2]\n",
    "\n",
    "\n",
    "test_data012 = torch.cat([zeros, ones, twos])\n",
    "test_labels012 = torch.cat([torch.zeros((len(zeros),)), torch.ones((len(ones),)), 2.0*torch.ones((len(twos),))])\n",
    "\n",
    "# ADB: Qui ho notato che c'e' un problema: le immagini sono int8, ma devono essere float32.\n",
    "# Faccio la conversione e divido per 255.0 (cosi' i pixel sono fra 0.0 e 1.0).\n",
    "test_data012 = test_data012.type(torch.float32) / 255.0\n",
    "print(len(test_data012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2884\n"
     ]
    }
   ],
   "source": [
    "test_l = test_loader.dataset.test_labels\n",
    "test_d = test_loader.dataset.test_data\n",
    "\n",
    "threes = test_d[test_l == 3]\n",
    "fours = test_d[test_l == 4]\n",
    "fives = test_d[test_l == 5]\n",
    "\n",
    "test_data345 = torch.cat([threes, fours, fives])\n",
    "\n",
    "# ADB: Qui ho notato che c'e' un problema: le immagini sono int8, ma devono essere float32.\n",
    "# Faccio la conversione e divido per 255.0 (cosi' i pixel sono fra 0.0 e 1.0).\n",
    "test_data345 = test_data345.type(torch.float32) / 255.0\n",
    "print(len(test_data345))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso possiamo utilizzare i nuovi dataset creati per train, validation e test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Train012 80%\n",
    "train_ds012 = TensorDataset(train_data012, train_labels012)\n",
    "train_loader012 = torch.utils.data.DataLoader(train_ds012, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# Validation012 20%\n",
    "validation_ds012 = TensorDataset(val_data012, val_labels012)\n",
    "validation_loader012 = torch.utils.data.DataLoader(validation_ds012, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# Test012 all\n",
    "test_ds012 = TensorDataset(test_data012, test_labels012)\n",
    "test_loader012 = torch.utils.data.DataLoader(test_ds012, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# Test 012 senza etichette\n",
    "test_loader012NoLab = torch.utils.data.DataLoader(test_data012, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# Test345 all\n",
    "test_loader345 = torch.utils.data.DataLoader(test_data345, batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADB: Osservazioni\n",
    "\n",
    "- Dati IN DISTRIBUTION per training (il train_loader012 va bene per questo). \n",
    "- Dati IN DISTRIBUTION per validation (i.e. per monitorare quanto bene classifichiamo le classi IN DISTRIBUTION). NON abbiamo questi data per la validation per ora.  \n",
    "- Dati OUT OF DISTRIBUTION (OOD) per i test finali (questo abbiamo, ma abbiamo chiamato 'validation'). Non possiamo usare questi dati nella funzione validate() sotto, per esempio, perche' non abbiamo ettichette e perche' non sono IN DISTRIBUTION. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Proviamo a stampare le prime 10 immagini del train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# ADB: qui ho modificato perche' ora ogni batch contiene un gruppo di immagini e anche un gruppo di label.\n",
    "for (X_train, y_train) in train_loader012:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :].numpy().reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Proviamo a stampare le prime 10 immagini del validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_train: torch.Size([32, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "for (V_train, y_train) in validation_loader012:\n",
    "    print('V_train:', V_train.size(), 'type:', V_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(V_train[i, :, :].numpy().reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Proviamo a stampare le prime 10 immagini del test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_train: torch.Size([32, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "for (T_train, y_train) in test_loader012:\n",
    "    print('T_train:', T_train.size(), 'type:', T_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(V_train[i, :, :].numpy().reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train: torch.Size([32, 28, 28]) type: torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "for Y_train in test_loader345:\n",
    "    print('Y_train:', Y_train.size(), 'type:', Y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(Y_train[i, :, :].numpy().reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron\n",
    "Definiamo ora la rete neurale come una Python class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc1_drop): Dropout(p=0.2)\n",
      "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2_drop): Dropout(p=0.2)\n",
      "  (fc3): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc1_drop = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc2_drop = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(128, 3)     # Numero di output 3.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc2_drop(x)\n",
    "        return F.log_softmax(self.fc3(x), 1)\n",
    "\n",
    "model = Net()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo le funzioni di **train** e **test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----con l'entropia\n",
    "#import torch.optim as optim\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch, log_interval=100):\n",
    "    model.train()\n",
    "    batch_idx = 0\n",
    "    while(batch_idx != len(train_loader012)):\n",
    "        for (data, target) in train_loader012:\n",
    "            target = target.type(torch.long)\n",
    "            if cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            #loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader012.dataset),\n",
    "                    100. * batch_idx / len(train_loader012), loss.item()))\n",
    "            batch_idx = batch_idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in validation_loader012:\n",
    "        target = target.type(torch.long)\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        val_loss += F.nll_loss(output, target).item()\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    val_loss /= len(validation_loader012)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct / len(validation_loader012.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader012.dataset), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, loader):\n",
    "    model.eval ()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in loader:\n",
    "        target = target.type(torch.long)\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data = Variable(data)\n",
    "        target = Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss (output, target).item ()  # sum up batch loss\n",
    "        pred = output.max (1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "        correct += pred.eq (target.view_as (pred)).sum ().item ()\n",
    "    test_loss /= len (loader.dataset)\n",
    "    print ('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format (\n",
    "        test_loss, correct, len (loader.dataset),\n",
    "        100. * correct / len (loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader):\n",
    "    preds = []\n",
    "    for data in data_loader :\n",
    "        data = Variable(data)\n",
    "        preds.append(model(data))\n",
    "        output = model(data)\n",
    "    preds = torch.cat(preds)\n",
    "    preds = torch.exp(preds)\n",
    "    preds = preds.detach()\n",
    "    preds = preds.numpy()\n",
    "    preds = np.matrix(preds)\n",
    "    print('\\nLe probabilità di classificazione sono: ')\n",
    "    print('')\n",
    "    print(preds)\n",
    "    idness = np.max(preds, 1)\n",
    "    print ('\\nLa max probabilità è: ')\n",
    "    print(idness)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo adesso addestrare il nostro modello, ogni epoca passa attraverso tutto il dataset del train. Dopo ogni epoca valutiamo il modello attraverso il test(). L'obiettivo è verificare che il modello riconosce come 0, 1, 2 anche le immagini di 3, 4, 5 quindi la classificazione è **out of distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/14961 (0%)]\tLoss: 0.018424\n",
      "Train Epoch: 1 [3200/14961 (21%)]\tLoss: 0.016131\n",
      "Train Epoch: 1 [6400/14961 (43%)]\tLoss: 0.033128\n",
      "Train Epoch: 1 [9600/14961 (64%)]\tLoss: 0.084158\n",
      "Train Epoch: 1 [12800/14961 (85%)]\tLoss: 0.064908\n",
      "\n",
      "Validation set: Average loss: 0.0403, Accuracy: 3611/3662 (98%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 3119/3147 (99%)\n",
      "\n",
      "\n",
      "DATASET 012\n",
      "\n",
      "Le probabilità di classificazione sono: \n",
      "\n",
      "[[8.7452133e-04 9.9339861e-01 5.7269572e-03]\n",
      " [3.5342466e-05 3.1449352e-05 9.9993324e-01]\n",
      " [9.9861670e-01 1.8073291e-04 1.2027605e-03]\n",
      " ...\n",
      " [9.9112644e-05 9.9837387e-01 1.5272081e-03]\n",
      " [9.3945134e-01 3.3550023e-04 6.0213048e-02]\n",
      " [9.0822607e-01 9.7306001e-05 9.1676697e-02]]\n",
      "\n",
      "La max probabilità è: \n",
      "[[0.9933986 ]\n",
      " [0.99993324]\n",
      " [0.9986167 ]\n",
      " ...\n",
      " [0.99837387]\n",
      " [0.93945134]\n",
      " [0.9082261 ]]\n",
      "\n",
      "\n",
      "DATASET 345\n",
      "\n",
      "Le probabilità di classificazione sono: \n",
      "\n",
      "[[6.4116359e-02 1.5496916e-02 9.2038673e-01]\n",
      " [8.4955292e-04 1.3216431e-03 9.9782896e-01]\n",
      " [1.8910196e-01 6.1976576e-01 1.9113225e-01]\n",
      " ...\n",
      " [2.1815964e-03 3.0741710e-04 9.9751115e-01]\n",
      " [8.3364153e-01 2.7290143e-03 1.6362944e-01]\n",
      " [2.5706859e-03 9.7661263e-01 2.0816561e-02]]\n",
      "\n",
      "La max probabilità è: \n",
      "[[0.92038673]\n",
      " [0.99782896]\n",
      " [0.61976576]\n",
      " ...\n",
      " [0.99751115]\n",
      " [0.8336415 ]\n",
      " [0.9766126 ]]\n",
      "\n",
      "\n",
      "Le probabilità di classificazione sono: \n",
      "\n",
      "[[7.9734135e-01 1.1068911e-03 2.0155169e-01]\n",
      " [9.9981451e-01 6.0024086e-06 1.7965732e-04]\n",
      " [9.9997234e-01 3.1634616e-07 2.6939490e-05]\n",
      " ...\n",
      " [9.9938601e-01 1.7652198e-06 6.1237736e-04]\n",
      " [4.0919032e-05 6.3186354e-07 9.9995804e-01]\n",
      " [1.6532800e-05 9.9930692e-01 6.7662570e-04]]\n",
      "\n",
      "La max probabilità è: \n",
      "[[0.79734135]\n",
      " [0.9998145 ]\n",
      " [0.99997234]\n",
      " ...\n",
      " [0.999386  ]\n",
      " [0.99995804]\n",
      " [0.9993069 ]]\n",
      "\n",
      "Le probabilità di classificazione sono: \n",
      "\n",
      "[[6.9160908e-01 1.2695846e-05 3.0837819e-01]\n",
      " [5.7441790e-02 1.1376002e-02 9.3118227e-01]\n",
      " [5.2232545e-02 7.0199347e-01 2.4577394e-01]\n",
      " ...\n",
      " [3.6060198e-03 1.5132639e-03 9.9488050e-01]\n",
      " [1.1775611e-02 6.6784906e-01 3.2037544e-01]\n",
      " [1.6466375e-02 1.1977881e-01 8.6375487e-01]]\n",
      "\n",
      "La max probabilità è: \n",
      "[[0.6916091 ]\n",
      " [0.93118227]\n",
      " [0.70199347]\n",
      " ...\n",
      " [0.9948805 ]\n",
      " [0.66784906]\n",
      " [0.86375487]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "continuous-multioutput format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-426e4821994d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader345\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader012NoLab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader345\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m     return _average_binary_score(_binary_uninterpolated_average_precision,\n\u001b[1;32m    198\u001b[0m                                  \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: continuous-multioutput format is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "\n",
    "#test_loader012\n",
    "test(epoch, test_loader012)\n",
    "\n",
    "print('\\nDATASET 012')\n",
    "predict(test_loader012NoLab)\n",
    "print('')\n",
    "print('\\nDATASET 345')\n",
    "predict(test_loader345)\n",
    "print('')\n",
    "average_precision_score(predict(test_loader012NoLab), predict(test_loader345))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
